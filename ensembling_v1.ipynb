{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "\n",
    "\n",
    "def get_metrics(model, axis, preprocessed_test=None):\n",
    "    prob_preds = model.predict_proba(x_train)\n",
    "    performance = roc_auc_score(y_train, prob_preds[:, axis])\n",
    "    print \"TRAINING: \" + str(performance)\n",
    "    \n",
    "    prob_preds = model.predict_proba(x_test)\n",
    "    performance = roc_auc_score(y_test, prob_preds[:, axis])\n",
    "    print \"TEST: \" + str(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.load(\"data/x_normalized.npy\")\n",
    "y = np.load(\"data/y.npy\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9881389025222007\n",
      "0.7976760596588771\n"
     ]
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(boosting_type='dart',learning_rate=0.1, num_leaves=500, reg_alpha=0, min_child_samples=5, min_child_weight=1e-05, n_estimators=1000, reg_lambda=100, max_depth=15, dropout=0.7)\n",
    "model.fit(x_train, y_train, verbose=False)\n",
    "\n",
    "y_pred = model.predict_proba(x_train)[:, 1]\n",
    "performance = roc_auc_score(y_train, y_pred)\n",
    "print performance\n",
    "\n",
    "y_pred = model.predict_proba(x_test)[:, 1]\n",
    "performance = roc_auc_score(y_test, y_pred)\n",
    "print performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9104873405681265\n",
      "0.7978625901336096\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model1 = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.6, gamma=1, learning_rate=0.05, max_delta_step=0,\n",
    "       max_depth=10, min_child_weight=10, missing=None, n_estimators=200,\n",
    "       n_jobs=1, nthread=1, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=0.8)\n",
    "model1.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model1.predict_proba(x_train)[:, 1]\n",
    "performance = roc_auc_score(y_train, y_pred)\n",
    "print performance\n",
    "\n",
    "y_pred = model1.predict_proba(x_test)[:, 1]\n",
    "performance = roc_auc_score(y_test, y_pred)\n",
    "print performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgboost_predictions = model.predict_proba(x_train)[:, 1]\n",
    "lgb_predictions = model1.predict_proba(x_train)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14159794, 0.42136143, 0.08245563, ..., 0.19948283, 0.62061479,\n",
       "       0.05624542])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2386743 , 0.38075927, 0.12050674, ..., 0.24197845, 0.59291583,\n",
       "       0.09094482], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgboost_predictions = xgboost_predictions.reshape(-1,1)\n",
    "lgb_predictions = lgb_predictions.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51733, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x_train = np.concatenate((xgboost_predictions, lgb_predictions), axis=1)\n",
    "new_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgboost_predictions = model.predict_proba(x_test)[:, 1]\n",
    "lgb_predictions = model1.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgboost_predictions = xgboost_predictions.reshape(-1,1)\n",
    "lgb_predictions = lgb_predictions.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x_test = np.concatenate((xgboost_predictions, lgb_predictions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12934, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"hehe/new_x_train.npy\", new_x_train)\n",
    "np.save(\"hehe/y_train.npy\", y_train)\n",
    "np.save(\"hehe/new_x_test.npy\", new_x_test)\n",
    "np.save(\"hehe/y_test.npy\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl_filename = \"hehe/best_xgboost.pkl\"  \n",
    "with open(pkl_filename, 'wb') as file:  \n",
    "    pickle.dump(model, file)\n",
    "    \n",
    "pkl_filename = \"hehe/best_lgb.pkl\"  \n",
    "with open(pkl_filename, 'wb') as file:  \n",
    "    pickle.dump(model1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
